{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from gensim import models\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "import os.path\n",
    "import urllib\n",
    "import gzip\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_tags(entity, search):\n",
    "    \"\"\"\n",
    "    This function searches through all the 'tags' (semantic content) of a data set\n",
    "    and returns 'true' if the search expression is found. case insensitive.\n",
    "    \"\"\"\n",
    "    all_tags = '; '.join([str(x) for x in entity['tags'].values()])\n",
    "    return bool(re.search(search, all_tags, flags=re.IGNORECASE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gunzipFile(inFileName, outFileName):\n",
    "    inF = gzip.open(inFileName, 'rb')\n",
    "    outF = open(outFileName, 'wb')\n",
    "    outF.write( inF.read() )\n",
    "    inF.close()\n",
    "    outF.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jaccardDistance(sent1, sent2, stoplist):\n",
    "    sent1 = re.sub('[^0-9a-zA-Z]+', ' ', sent1)\n",
    "    sent2 = re.sub('[^0-9a-zA-Z]+', ' ', sent2)\n",
    "    tokens1 = [word for word in sent1.replace(\"…\", \" \").lower().split() if word not in stoplist]\n",
    "    tokens2 = [word for word in sent2.replace(\"…\", \" \").lower().split() if word not in stoplist]\n",
    "    \n",
    "    # subtract from 1, so that 0 means all words in common and 1 means no words in common\n",
    "    jaccardIndex = 1.0 - float(len(set.intersection(set(tokens1), set(tokens2)))) / float(len(set.union(set(tokens1), set(tokens2))))\n",
    "    return(jaccardIndex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the stopwords file. These are common words which we wish to exclude when performing comparisons (a, an, the, etc). Every word is separated by a new line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopWordsFile = \"en.txt\"\n",
    "with open(stopWordsFile) as f:\n",
    "    stoplist = [x.strip('\\n') for x in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the data from the catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://stackoverflow.com/questions/956867/how-to-get-string-objects-instead-of-unicode-ones-from-json-in-python\n",
    "# need this to deal with unicode errors\n",
    "def byteify(input):\n",
    "    if isinstance(input, dict):\n",
    "        return {byteify(key): byteify(value)\n",
    "                for key, value in input.iteritems()}\n",
    "    elif isinstance(input, list):\n",
    "        return [byteify(element) for element in input]\n",
    "    elif isinstance(input, unicode):\n",
    "        return input.encode('utf-8')\n",
    "    else:\n",
    "        return input\n",
    "\n",
    "gunzipFile('../catalogs/gabi_2016_professional-database-2016.json.gz', \n",
    "           '../catalogs/gabi_2016_professional-database-2016.json')\n",
    "gunzipFile('../catalogs/uslci_ecospold.json.gz', \n",
    "           '../catalogs/uslci_ecospold.json')\n",
    "\n",
    "with open('../catalogs/gabi_2016_professional-database-2016.json') as data_file:    \n",
    "    gabi = json.load(data_file, encoding='utf-8')\n",
    "\n",
    "with open('../catalogs/uslci_ecospold.json') as data_file:    \n",
    "    uslci = json.load(data_file, encoding='utf-8')\n",
    "    \n",
    "gabi = byteify(gabi)\n",
    "uslci = byteify(uslci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process name to match:\n",
      "Roundwood, softwood, average, at forest road, NE-NC\n",
      "Matches using Word2Vec:\n",
      "('Road (average)', 0.7142857142857143)\n",
      "('Federal road', 0.875)\n",
      "('Land road', 0.875)\n",
      "('Municipal road', 0.875)\n",
      "('County road', 0.875)\n",
      "('Industrial road', 0.875)\n",
      "('Cement (average)', 0.875)\n",
      "('Softwood plywood', 0.875)\n",
      "('Softwood lumber', 0.875)\n",
      "('Crude oil, at consumer Ireland', 1.0)\n"
     ]
    }
   ],
   "source": [
    "roundwood = [flow for flow in uslci['flows'] if search_tags(flow,'roundwood, softwood')]\n",
    "roundwoodExample = roundwood[0]\n",
    "\n",
    "# number of top scores to show\n",
    "numTopScores = 10\n",
    "\n",
    "flowNames = []\n",
    "distValues = []\n",
    "for flow in gabi['archives'][0]['flows']:\n",
    "    name = flow['tags']['Name']\n",
    "    flowNames.append(name)\n",
    "    dist = jaccardDistance(roundwoodExample['tags']['Name'], name, stoplist)\n",
    "    distValues.append(dist)\n",
    "\n",
    "len(flowNames)\n",
    "    \n",
    "# figure out top scores\n",
    "arr = np.array(distValues)\n",
    "topIndices = arr.argsort()[0:numTopScores]\n",
    "topScores = np.array(distValues)[topIndices]\n",
    "\n",
    "print 'Process name to match:'\n",
    "print roundwoodExample['tags']['Name']\n",
    "\n",
    "print 'Matches using Word2Vec:'\n",
    "for i, s in zip(topIndices, topScores):\n",
    "    if s < 9999:\n",
    "        print(flowNames[i],s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
